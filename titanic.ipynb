{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\AppData\\Local\\Temp\\ipykernel_6472\\762718783.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data=data.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Shaurya\\\\Downloads\\\\titanic.csv\")\n",
    "data.Sex=data.Sex.replace({'male':0,'female':1})\n",
    "data.Embarked=data.Embarked.replace({'Q':0,'C':1,'S':2})\n",
    "data=data.fillna(method='bfill')\n",
    "#data.Age.replace('NaN',data.Age.mean())\n",
    "#data.Embarked.replace('NaN','0')\n",
    "X = data[['Pclass','Age','Embarked','Sex']]\n",
    "y = data['Survived']\n",
    "for i in X.T:\n",
    "    fmin = X.min()\n",
    "    frange = X.max() - X.min()\n",
    "    X -= fmin\n",
    "    X /= frange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros(X_train.shape[1])\n",
    "lr = 0.5\n",
    "num_iterations = 4000\n",
    "cost_history = []\n",
    "print(weights)\n",
    "bias=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, weights):\n",
    "\n",
    "    z = np.dot(X_train, weights)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X_train, y_train, weights):\n",
    "    \n",
    "    observations = len(y_train)\n",
    "    predictions = predict(X_train, weights)\n",
    "\n",
    "    class1_cost = -y_train*np.log(predictions)\n",
    "\n",
    "    class2_cost = (1-y_train)*np.log(1-predictions)\n",
    "\n",
    "    cost = class1_cost - class2_cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost\n",
    "#Squaring this prediction as we do in MSE results in a non-convex function with many local minimums. If our cost function has many local minimums, gradient descent may not find the optimal global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(X_train, y_train, weights, lr):\n",
    "    N = len(X_train)\n",
    "    predictions = predict(X_train, weights)\n",
    "    gradient = np.dot(X_train.T,  predictions - y_train)\n",
    "    gradient /= N\n",
    "    gradient *= lr\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(prob):\n",
    "     return 1 if prob >= .5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions):\n",
    "#    decision_boundary = np.vectorize(decision_boundary)\n",
    "#    return decision_boundary(predictions).flatten()\n",
    "    #predictions = np.vectorize(predictions).all()\n",
    "    predictions1=list(predictions)\n",
    "    for i in range(len(predictions1)):\n",
    "        if((predictions1[i]>=0.65).any()):\n",
    "            predictions1[i]=1.0\n",
    "        else: predictions1[i]=0.0\n",
    "    return predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, weights, lr, num_iterations):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        weights = update_weights(X_train, y_train, weights, lr)\n",
    "\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(X_train, y_train, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print(\"iter: \" +str(i) + \" cost: \"+str(cost))\n",
    "\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 cost: 0.6723396935848419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000 cost: 0.4632372491555939\n",
      "iter: 2000 cost: 0.4632355147323549\n",
      "iter: 3000 cost: 0.4632355125211349\n",
      "[0.10956798 0.20080773 0.10247002 0.81474518 0.6532441  0.89931373\n",
      " 0.66803642 0.10580102 0.67394853 0.90483253 0.36637591 0.08437584\n",
      " 0.5830337  0.10445054 0.19374007 0.90711379 0.35607725 0.67001313\n",
      " 0.20659957 0.34591003 0.09923225 0.37261495 0.6172925  0.10247002\n",
      " 0.1008396  0.11097642 0.38604817 0.20080773 0.11637203 0.59168796\n",
      " 0.10329396 0.61094612 0.41822871 0.5633813  0.10412375 0.10698233\n",
      " 0.38521932 0.65806483 0.90589712 0.0900595  0.21551728 0.09531329\n",
      " 0.09302889 0.12863044 0.58821523 0.10580102 0.10329396 0.10003306\n",
      " 0.09923225 0.34872672 0.67121226 0.8762643  0.08717578 0.42172567\n",
      " 0.08702231 0.90559847 0.19937891 0.88953466 0.77246093 0.66803642\n",
      " 0.10165191 0.80512731 0.78325701 0.38521932 0.10477824 0.73611344\n",
      " 0.21551728 0.09531329 0.11581498 0.88776803 0.78627268 0.91464066\n",
      " 0.41605824 0.89882111 0.10003306 0.0900595  0.64489103 0.91181123\n",
      " 0.76771944 0.56995743 0.10580102 0.78173768 0.89800638 0.10394384\n",
      " 0.35279254 0.32285283 0.90513335 0.90589712 0.36430603 0.09531329\n",
      " 0.11186023 0.63814968 0.31820254 0.12763317 0.11931371 0.09608584\n",
      " 0.34389302 0.08368873 0.77088805 0.09686398 0.31242089 0.09079374\n",
      " 0.91394112 0.08860705 0.09416488 0.09843716 0.76452038 0.34591003\n",
      " 0.0945463  0.38604817 0.88741899 0.10206024 0.92390592 0.36845073\n",
      " 0.36224117 0.10247002 0.32285283 0.21160697 0.79221201 0.55457874\n",
      " 0.21251404 0.90436404 0.86521798 0.24751211 0.09843716 0.39667967\n",
      " 0.8791389  0.42040235 0.61600922 0.10165191 0.62524004 0.10528853\n",
      " 0.17496106 0.64635386 0.36718844 0.65121923 0.91533505 0.09531329\n",
      " 0.08576546 0.61939922 0.10165191 0.75803129 0.20514012 0.19234943\n",
      " 0.62732943 0.77402617 0.2022442  0.15528994 0.87469936 0.08506808\n",
      " 0.11490396 0.09923225 0.10412375 0.61048724 0.11931371 0.09079374\n",
      " 0.11938877 0.64998521 0.77088805 0.64181859 0.11000421 0.38521932\n",
      " 0.18959101 0.91181123 0.09514698 0.33467184 0.21251404 0.87818716\n",
      " 0.1008396  0.09079374 0.42257908 0.79802868 0.36845073 0.66328434\n",
      " 0.10495943 0.08604017 0.57650896 0.7994637  0.64839173]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights,cost_history=train(X_train, y_train, weights, lr, num_iterations)\n",
    "predictions_test = sigmoid(np.dot(X_test, weights))\n",
    "print(predictions_test)\n",
    "predictions_test=classify(predictions_test)\n",
    "\n",
    "c=confusion_matrix(y_test,predictions_test)\n",
    "accuracy=(c[0][0]+c[1][1])/len(y_test)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
